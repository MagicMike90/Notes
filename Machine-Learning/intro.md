# Introduction

Machine learning summarized in four categories.

- Predictive learning: comprises two kinds of tasks where we aim to either predict a continuous valued phenomenon (like the future location of a celestial body), or distinguish between distinct kings of things (like different faces in an image)
- Feature design: A broad set of engineering and mathematical tools which are crucial to the successful performance of predictive learning models in practice.
- Function approximation: It is employed when we know too little abut a dataset to produce proper features ourselves (and therefore must learn them strictly from the data itself).
- Numerical optimization  powers the first three and is the engine that makes machine learning run in practice.

## Three types of machine learning

- Supervised learning (making predictions about the future):
  - **supervised** refers to a set of samples where the desired output signals (lables ) are already known.
  - There are two sub categories:
    - classification : the goal is to predict the categorical class labels of new instances based on the pas observations.
      - i.e. distinguish spam and non-spam email
    - regression: for predicting continuous outcomes, given a number of *predictor* ( explanatory) variables and a continuous response variable (outcome), and we try to find a relationship between those variables that allows us to predict an outcome.
      - i.e. predict a relationship between the time spent studying for the test and the final scores

- Unsupervised learning:
- reinforcement learning:

## Basic process

1. Define task
2. Collect data
3. Design features
4. Train model
5. Test model

## Predictive learning problems

1. Regression:
2. Classification: The key difference between the two is that instead of predicting a continuous-valued output (e.g., share price blood pressure, etc.), with classification what we aim at predicting takes on discrete values or classes.

## Regression




